# AI News — Feb 26, 2026
**Created**: Session #234 — 6 fresh angles for future content (N33-N38)

**Usage**: Queue <15 on both platforms → pick highest-priority angle, apply publishing skill templates.
**Priority**: Deploy N27+N28 first (from ai-news-2026-02-25.md), then these.

---

## News Angles (Priority Order)

**N33: xAI $20B Series E — Grok 5 in Training**
Hook: "$20 billion. Grok 5 in training. xAI is now worth over $100B. Elon's AI bet is paying off."
Data: xAI raised $20B Series E (Jan 6, 2026). Investors: NVIDIA, Cisco, Qatar Investment Authority, Fidelity. 600M monthly active users of X + Grok. Grok 5 currently in training. 1M+ H100 GPU equivalents at Colossus I+II (South Memphis). Despite controversy (CSAM generation + regulatory probes in EU, Malaysia, India), funding demand stayed strong.
Angle: Dollar amount shock, Grok 5 anticipation, controversy angle — high shareability
Source: https://x.ai/news/series-e

**N34: DeepSeek's Silent Upgrade — 8x Bigger Context, $0.10/1M Tokens**
Hook: "DeepSeek silently upgraded from 128K to 1 million tokens. No announcement. No press release. Just did it."
Data: Silent rollout Feb 11, 2026. "Long-text model test" announcement Feb 14. 8x context increase. Maintains >60% accuracy at 1M tokens. DeepSeek V4 (1T params, 32B active via MoE) expected Q1-Q2 2026. Projected pricing: $0.10/1M input tokens (50x cheaper than GPT-5.2). Engram memory = O(1) retrieval = no cost penalty for long context.
Angle: Stealth launch hook, price shock ($0.10 vs $5+), technical depth — developer audience
Source: https://ai-engineering-trend.medium.com/deepseek-v4-preview-million-token-context-window-and-inference-acceleration-73496d89f814

**N35: Perplexity Model Council — Running Claude + GPT-5.2 + Gemini Simultaneously**
Hook: "Perplexity now runs Claude, GPT-5.2, and Gemini in parallel on the same question. One answer, three perspectives. The single-model era is ending."
Data: Launched Feb 5, 2026. Runs 3 models in parallel → synthesizer model compiles results. Shows agreement, differences, unique insights. Available to Max subscribers. Use cases: investment research, complex decisions, factual verification. Models used: Claude Opus 4.6, GPT-5.2, Gemini 3.0.
Angle: Paradigm shift hook, multi-model future, tech audience
Source: https://www.perplexity.ai/hub/blog/introducing-model-council

**N36: Claude Opus 4.6 — 80.9% on SWE-bench vs GPT-5.2's 70%**
Hook: "Claude Opus 4.6 codes better than GPT-5.2. 80.9% vs 70% on SWE-bench. OpenAI is in second place for coding."
Data: Claude Opus 4.6 (released Feb 5, 2026). Agent teams, PowerPoint integration, 1M token context. 80.9% SWE-bench Verified vs GPT-5.2's ~70% and Gemini's ~65%. Led OpenAI to declare "code red." Computer use: 72.5% on OSWorld (up from 14.9% on Claude 3.5).
Angle: Benchmark shock, competitive angle, coding/dev audience
Note: Tie to Anthropic's $380B valuation (N28) for narrative coherence

**N37: GPT-5.3-Codex Released + OpenAI Tests Ads in ChatGPT**
Hook: "OpenAI just launched GPT-5.3-Codex and is now testing ads in ChatGPT. The free tier just got a price."
Data: GPT-5.3-Codex released Feb 5, 2026 (same day as Claude Opus 4.6). GPT-5.2 retired GPT-4o, GPT-4.1, o4-mini from ChatGPT. OpenAI testing ads for Free + Go tier users. Plus/Pro/Business remain ad-free. $13.1B revenue last year, $280B target by 2030. 900M WAU ChatGPT.
Angle: Ads controversy hook, timeline of model war, monetization angle
Source: https://releasebot.io/updates/openai

**N38: MatX — $500M to Build 10x Faster AI Chips**
Hook: "$500M to build chips 10x faster than NVIDIA's H100. If MatX delivers, the GPU supply chain changes forever."
Data: MatX raised $500M Series B (Jane Street, Situational Awareness, Marvell, Stripe co-founders). Designs semiconductor accelerators for LLM training. Claims ~10x performance vs current GPUs. Sample shipments targeted for 2027. U.S.-focused AI chip play amid China supply chain concerns.
Angle: Competitive NVIDIA angle, money amount, hardware moonshot — tech audience
Source: https://radicaldatascience.wordpress.com/2026/02/20/ai-news-briefs-bulletin-board-for-february-2026/

---

## Priority Deployment Order
1. **N33** (xAI $20B, Grok 5 in training)
2. **N34** (DeepSeek silent 1M token upgrade)
3. **N35** (Perplexity Model Council multi-model)
4. **N36** (Claude Opus 4.6 vs GPT-5.2 benchmark)
5. **N37** (GPT-5.3 + ads in ChatGPT)
6. **N38** (MatX $500M 10x GPU chips)

**Note**: Deploy N27+N28 from ai-news-2026-02-25.md first (those are still queued/pending).

---

## Context for Session Planning
- Bluesky queue was at 15 when this research was created (needed to drain)
- X queue was at 9 when this research was created
- Session #234 created this research file instead of content (queue constraint)
- Target: When Bluesky drains to <15, start deploying N27+N28, then N33+ from this file
